{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaveDB Mapping Analysis\n",
    "\n",
    "This notebook demonstrates how data from score sets in [MaveDB](https://mavedb.org/) can be mapped to human reference sequences and represented using the [Variation Representation Specification (VRS)](https://vrs.ga4gh.org/) of the [Global Alliance for Genomics and Health (GA4GH)](https://www.ga4gh.org/), as described in \"Mapping MAVE data for use in human genomics applications\" (Arbesfeld et al). After each step of the mapping pipeline, data is saved to a local [pickle](https://docs.python.org/3/library/pickle.html) checkpoint file for easy use in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, initialize environment parameters to enable access to required resources:\n",
    "\n",
    "* Universal Transcript Archive (UTA): see [README](https://github.com/biocommons/uta?tab=readme-ov-file#installing-uta-locally) for setup instructions. Users with access to Docker on their local devices can use the available Docker image; otherwise, start a relatively recent (version 14+) PostgreSQL instance and add data from the available database dump.\n",
    "* SeqRepo: see [README](https://github.com/biocommons/biocommons.seqrepo?tab=readme-ov-file#requirements) for setup instructions.\n",
    "* Gene Normalizer: see [documentation](https://gene-normalizer.readthedocs.io/0.3.0-dev1/install.html) for installation instructions\n",
    "* blat: Must be available on the local PATH and executable by the user. Otherwise, its location can be set manually with the BLAT_BIN_PATH env var. See the [UCSC Genome Browser FAQ](https://genome.ucsc.edu/FAQ/FAQblat.html#blat3) for download instructions. For our experiments, we placed the binary in the same directory as these notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set external resources\n",
    "environ[\"GENE_NORM_DB_URL\"] = \"postgresql://postgres@localhost:5432/gene_normalizer\"\n",
    "environ[\"UTA_DB_URL\"] = \"postgresql://uta_admin:uta@localhost:5432/uta/uta_20210129b\"\n",
    "environ[\"BLAT_BIN_PATH\"] = str(Path(\"blat\").absolute())\n",
    "environ[\"SEQREPO_ROOT_DIR\"] = \"/usr/local/share/seqrepo/2024-02-20\"  # TODO or latest/\n",
    "environ[\"DCD_MAPPING_RESOURCES_DIR\"] = str(Path(\"./mavedb_files\").absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Output Directory\n",
    "\n",
    "Output from this notebook will be stored in a directory named `analysis_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_files_dir = Path(\"analysis_files\")\n",
    "analysis_files_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get experiment data from MaveDB\n",
    "\n",
    "Get metadata for the examined MaveDB score sets (209 in total). Each captures the following:\n",
    "\n",
    "* `urn`: The score set identifier\n",
    "* `target_gene_name`: The listed target for the score set (e.g. Src catalytic domain, CXCR4)\n",
    "* `target_sequence`: The target sequence for the score set\n",
    "* `target_sequence_type`: Is the target sequence a DNA or protein sequence\n",
    "* `target_uniprot_ref`: The Uniprot ID associated with the score set, if available\n",
    "* `target_gene_category`: The target type associated with the score set (e.g. Regulatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiment_scoresets.txt\") as f:\n",
    "    #. scoresets = [scoreset.strip() for scoreset in f.readlines()]     # TODO use this delete the other\n",
    "    scoresets = [scoreset.strip() for scoreset in f.readlines()][:5]\n",
    "example_scoreset = \"urn:mavedb:00000041-a-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 2329.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'urn': 'urn:mavedb:00000041-a-1',\n",
       " 'target_gene_name': 'Src catalytic domain',\n",
       " 'target_gene_category': <TargetType.PROTEIN_CODING: 'Protein coding'>,\n",
       " 'target_sequence': 'CTGCGGCTGGAGGTCAAGCTGGGCCAGGGCTGCTTTGGCGAGGTGTGGATGGGGACCTGGAACGGTACCACCAGGGTGGCCATCAAAACCCTGAAGCCTGGCACGATGTCTCCAGAGGCCTTCCTGCAGGAGGCCCAGGTCATGAAGAAGCTGAGGCATGAGAAGCTGGTGCAGTTGTATGCTGTGGTTTCAGAGGAGCCCATTTACATCGTCACGGAGTACATGAGCAAGGGGAGTTTGCTGGACTTTCTCAAGGGGGAGACAGGCAAGTACCTGCGGCTGCCTCAGCTGGTGGACATGGCTGCTCAGATCGCCTCAGGCATGGCGTACGTGGAGCGGATGAACTACGTCCACCGGGACCTTCGTGCAGCCAACATCCTGGTGGGAGAGAACCTGGTGTGCAAAGTGGCCGACTTTGGGCTGGCTCGGCTCATTGAAGACAATGAGTACACGGCGCGGCAAGGTGCCAAATTCCCCATCAAGTGGACGGCTCCAGAAGCTGCCCTCTATGGCCGCTTCACCATCAAGTCGGACGTGTGGTCCTTCGGGATCCTGCTGACTGAGCTCACCACAAAGGGACGGGTGCCCTACCCTGGGATGGTGAACCGCGAGGTGCTGGACCAGGTGGAGCGGGGCTACCGGATGCCCTGCCCGCCGGAGTGTCCCGAGTCCCTGCACGACCTCATGTGCCAGTGCTGGCGGAAGGAGCCTGAGGAGCGGCCCACCTTCGAGTACCTGCAGGCCTTCCTG',\n",
       " 'target_sequence_type': <TargetSequenceType.DNA: 'dna'>,\n",
       " 'target_uniprot_ref': {'id': 'uniprot:P12931', 'offset': 269}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dcd_mapping.mavedb_data import get_scoreset_metadata\n",
    "\n",
    "metadata = {}\n",
    "for scoreset in tqdm(scoresets):\n",
    "    metadata[scoreset] = get_scoreset_metadata(scoreset)\n",
    "metadata[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, get corresponding experiment scores from MaveDB. Mirroring information provided by `/scores` API endpoint, provides the following data for each score in a score set:\n",
    "\n",
    "* `hgvs_pro`: variant description with respect to the amino acid target sequence\n",
    "* `hgvs_nt`: variant description with respect to the nucleotide target sequence\n",
    "* `score`: raw reported score\n",
    "* `accession`: accession identifier for the specific experiment, e.g. `urn:mavedb:00000041-a-1#548`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 56.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hgvs_pro': 'p.Tyr170Gly',\n",
       " 'hgvs_nt': 'NA',\n",
       " 'score': '0.753146338',\n",
       " 'accession': 'urn:mavedb:00000041-a-1#36'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dcd_mapping.mavedb_data import get_scoreset_records\n",
    "\n",
    "scores = {}\n",
    "for urn in tqdm(scoresets):\n",
    "    try:\n",
    "        scores[urn] = get_scoreset_records(urn)\n",
    "    except:\n",
    "        print(urn)\n",
    "scores[example_scoreset][0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MaveDB Metadata to BLAT Alignment Data\n",
    "\n",
    "During this step, the target sequence for each score set is run through BLAT, allowing for genomic coordinates to be linked with the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BLAT Output for each Score Set\n",
    "\n",
    "Generate BLAT alignment output for each examined score set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:20<00:00, 28.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from dcd_mapping.align import AlignmentError, align\n",
    "from dcd_mapping.mavedb_data import get_scoreset_metadata\n",
    "\n",
    "align_results = {}\n",
    "failed_alignment_scoresets = []\n",
    "\n",
    "for scoreset, meta in tqdm(metadata.items()):\n",
    "    try:\n",
    "        align_results[scoreset] = align(meta, silent=True)\n",
    "    except AlignmentError:\n",
    "        failed_alignment_scoresets.append(scoreset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO more describe\n",
    "\n",
    "This scoreset fails BLAT explain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(failed_alignment_scoresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the alignment phase is a structured description of the best BLAT result for the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chrom': 'chr20',\n",
       " 'strand': <Strand.POSITIVE: 1>,\n",
       " 'coverage': 100.0,\n",
       " 'ident_pct': 99.86666666666666,\n",
       " 'query_range': {'start': 0, 'end': 750},\n",
       " 'query_subranges': [{'start': 0, 'end': 52},\n",
       "  {'start': 52, 'end': 232},\n",
       "  {'start': 232, 'end': 309},\n",
       "  {'start': 309, 'end': 463},\n",
       "  {'start': 463, 'end': 595},\n",
       "  {'start': 595, 'end': 750}],\n",
       " 'hit_range': {'start': 37397802, 'end': 37403325},\n",
       " 'hit_subranges': [{'start': 37397802, 'end': 37397854},\n",
       "  {'start': 37400114, 'end': 37400294},\n",
       "  {'start': 37401601, 'end': 37401678},\n",
       "  {'start': 37402434, 'end': 37402588},\n",
       "  {'start': 37402748, 'end': 37402880},\n",
       "  {'start': 37403170, 'end': 37403325}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_results[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save BLAT Output\n",
    "\n",
    "Save BLAT output locally to the `analysis_files` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "mave_blat_to_save = {}\n",
    "for scoreset in scoresets:\n",
    "    mave_blat_to_save[scoreset] = align_results[scoreset].dict()\n",
    "with Path.open(\"analysis_files/mave_blat_output.pickle\", \"wb\") as fn:\n",
    "    pickle.dump(mave_blat_to_save, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Transcript and Offset Selection for MaveDB Score Sets\n",
    "\n",
    "In this phase, a human transcript is chosen for each protein-coding score set, and an offset is computed when the target sequence does not occur at the start of the human reference sequence. For regulatory/other non-coding score sets, a transcript is not chosen and the chromosomal sequence is selected as the reference sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BLAT output\n",
    "\n",
    "Load the BLAT output for the examined MaveDB score sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.schemas import AlignmentResult\n",
    "\n",
    "with Path.open(\"analysis_files/mave_blat_output.pickle\", \"rb\") as fn:\n",
    "    mave_blat_temp = pickle.load(fn)\n",
    "align_results = {}\n",
    "for scoreset in scoresets:\n",
    "    align_results[scoreset] = AlignmentResult(**mave_blat_temp[scoreset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Transcript Mappings File\n",
    "\n",
    "Generate a transcript mapping for each relevant score set containing the following data:\n",
    "\n",
    "* `nm`: A RefSeq transcript accession\n",
    "* `np`: A RefSeq protein sequence accession\n",
    "* `start`: An integer containing the offset for the target sequence with the respect to the selected human reference sequence\n",
    "* `transcript_mode`: The set of [MANE annotations](https://www.ncbi.nlm.nih.gov/refseq/MANE/) in which the selected transcript is included. See the [CoolSeqTool docs](https://coolseqtool.readthedocs.io/0.4.0-dev3/transcript_selection.html#representative-transcript-priority) for additional information\n",
    "* `sequence`: The translated protein reference sequence\n",
    "* `is_full_match`: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from dcd_mapping.transcripts import TxSelectError, select_transcript\n",
    "\n",
    "nest_asyncio.apply()\n",
    "failed_tx_select_scoresets = [] \n",
    "tx_selection = {}\n",
    "for ss in scoresets:\n",
    "    if ss in align_results:\n",
    "        try:\n",
    "            tx_selection[ss] = asyncio.run(\n",
    "                select_transcript(\n",
    "                    metadata[ss],\n",
    "                    scores[ss],\n",
    "                    align_results[ss],\n",
    "                    silent=True\n",
    "                )\n",
    "            )\n",
    "        except TxSelectError:\n",
    "            failed_tx_select_scoresets.append(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nm': 'NM_198291.3',\n",
       " 'np': 'NP_938033.1',\n",
       " 'start': 269,\n",
       " 'is_full_match': True,\n",
       " 'transcript_mode': <TranscriptPriority.MANE_SELECT: 'mane_select'>,\n",
       " 'sequence': 'LRLEVKLGQGCFGEVWMGTWNGTTRVAIKTLKPGTMSPEAFLQEAQVMKKLRHEKLVQLYAVVSEEPIYIVTEYMSKGSLLDFLKGETGKYLRLPQLVDMAAQIASGMAYVERMNYVHRDLRAANILVGENLVCKVADFGLARLIEDNEYTARQGAKFPIKWTAPEAALYGRFTIKSDVWSFGILLTELTTKGRVPYPGMVNREVLDQVERGYRMPCPPECPESLHDLMCQCWRKEPEERPTFEYLQAFL'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_selection[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phase should be completed without encountering any errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_tx_select_scoresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Transcript Mappings Output\n",
    "\n",
    "Run the cell below to save the transcript_mappings file locally to the `analysis_files` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "transcript_mappings_to_save = {}\n",
    "for ss in tx_selection:\n",
    "    if tx_selection[ss]:\n",
    "        transcript_mappings_to_save[ss] = tx_selection[ss].dict()\n",
    "with Path.open(\"analysis_files/transcript_mappings.pickle\", \"wb\") as fn:\n",
    "    pickle.dump(transcript_mappings_to_save, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Mapping MAVE Variants using the GA4GH Variation Representation Specification (VRS)\n",
    "\n",
    "During this phase, MAVE variants are supplied to VRS, generating a pre-mapped and post-mapped computable representation for each variant. The functional effect score for each variant pair and the associated MaveDB ID are also stored in separate dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Alignment and Transcript Selection Data\n",
    "\n",
    "Run the cell below to load alignment and transcript selection data for each score set from the `analysis_files` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.schemas import AlignmentResult, TxSelectResult\n",
    "\n",
    "with Path.open(\"analysis_files/mave_blat_output.pickle\", \"rb\") as fn:\n",
    "    mave_blat_temp = pickle.load(fn)\n",
    "align_results = {}\n",
    "for ss in mave_blat_temp:\n",
    "    align_results[ss] = AlignmentResult(**mave_blat_temp[ss])\n",
    "\n",
    "with Path.open(\"analysis_files/transcript_mappings.pickle\", \"rb\") as fn:\n",
    "    transcript_mappings_temp = pickle.load(fn)\n",
    "tx_selection = {}\n",
    "for ss in transcript_mappings_temp:\n",
    "    tx_selection[ss] = TxSelectResult(**transcript_mappings_temp[ss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MaveDB Variants to VRS Alleles\n",
    "\n",
    "Convert MaveDB variants to VRS objects. Each MaveDB variant has a separate pre-mapped and post-mapped list of VRS alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_map_regulatory_noncoding() missing 1 required positional argument: 'sr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m mave_vrs_mappings \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ss \u001b[38;5;129;01min\u001b[39;00m align_results:\n\u001b[0;32m----> 8\u001b[0m     mave_vrs_mappings[ss] \u001b[38;5;241m=\u001b[39m \u001b[43mvrs_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_seqrepo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtranscript\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/mavemap/src/dcd_mapping/vrs_map.py:441\u001b[0m, in \u001b[0;36mvrs_map\u001b[0;34m(metadata, align_result, records, silent, transcript)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mTypeError\u001b[0m: _map_regulatory_noncoding() missing 1 required positional argument: 'sr'"
     ]
    }
   ],
   "source": [
    "from dcd_mapping.lookup import get_seqrepo\n",
    "from dcd_mapping.vrs_map import vrs_map\n",
    "from dcd_mapping.mavedb_data import get_scoreset_metadata, get_scoreset_records\n",
    "\n",
    "mave_vrs_mappings = {}\n",
    "\n",
    "for ss in align_results:\n",
    "    mave_vrs_mappings[ss] = vrs_map(\n",
    "        metadata[ss],\n",
    "        align_results[ss],\n",
    "        scores[ss],\n",
    "        tx_selection.get(ss)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VRS Mappings Dictionary\n",
    "\n",
    "Run the cell below to save the VRS mappings dictionary to `analysis_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with Path.open(\"analysis_files/mave_vrs_mappings.pickle\", \"wb\") as fn:\n",
    "    pickle.dump(mave_vrs_mappings, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in VRS Mappings Dictionary and Transcript Selection Dictionary\n",
    "\n",
    "Run the cell below to read in the VRS mappings dictionary and transcript selection dictionaries from `analysis_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.transcripts import TxSelectResult\n",
    "\n",
    "with Path.open(\"analysis_files/mave_vrs_mappings.pickle\", \"rb\") as fn:\n",
    "    mave_vrs_mappings = pickle.load(fn)\n",
    "with Path.open(\"analysis_files/transcript_mappings.pickle\", \"rb\") as fn:\n",
    "    transcript_mappings_temp = pickle.load(fn)\n",
    "tx_selection = {}\n",
    "for ss in transcript_mappings_temp:\n",
    "    tx_selection[ss] = TxSelectResult(**transcript_mappings_temp[ss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Annotations\n",
    "\n",
    "Run the cell below to generate annotations. These annotations are:\n",
    "1. `vrs_ref_allele_seq`: The sequence between the start and end positions indicated in the variant\n",
    "2. `hgvs`: An HGVS string describing the variant. This is only included for post-mapped variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def format_start_end(ss: str, start: int, end: int) -> List[int]:\n",
    "    \"\"\"Format start and end coordinates for vrs_ref_allele_seq for known edge\n",
    "    cases\n",
    "    :param ss: score set\n",
    "    :param start: start coordinate\n",
    "    :param end: end coordinate\n",
    "    :return A list of start and end coordinates\n",
    "    \"\"\"\n",
    "    if ss.startswith(\"urn:mavedb:00000060-a-1\"):\n",
    "        # This score set set reports the entire human reference sequence as the\n",
    "        # target sequence, but the positions in the score set occur with an offset\n",
    "        # of 289\n",
    "        return [start + 289, end + 289]\n",
    "    if ss.startswith(\"urn:mavedb:00000060-a-2\"):\n",
    "        # This score set set reports the entire human reference sequence as the\n",
    "        # target sequence, but the positions in the score set occur with an offset\n",
    "        # of 331\n",
    "        return [start + 331, end + 331]\n",
    "    return [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cool_seq_tool.schemas import AnnotationLayer\n",
    "\n",
    "from dcd_mapping.lookup import get_chromosome_identifier_from_vrs_id, get_seqrepo\n",
    "from dcd_mapping.utils import get_hgvs_string\n",
    "\n",
    "dp = get_seqrepo()\n",
    "\n",
    "for ss in mave_vrs_mappings:\n",
    "    print(ss)\n",
    "    for var in mave_vrs_mappings[ss].variations:\n",
    "    # Add vrs_ref_allele_seq annotation to pre-mapped variants\n",
    "        if not var:\n",
    "            continue\n",
    "        else:\n",
    "            variant_list = var.pre_mapped_variants\n",
    "        if \"members\" in variant_list:\n",
    "            for sub_var in variant_list[\"members\"]:\n",
    "                start_end = format_start_end(ss, start=sub_var[\"location\"]\n",
    "                                             [\"interval\"][\"start\"][\"value\"],\n",
    "                                             end=sub_var[\"location\"][\"interval\"]\n",
    "                                             [\"end\"][\"value\"])\n",
    "                if (ss.startswith((\"urn:mavedb:00000047\", \"urn:mavedb:00000048\",\n",
    "                                   \"urn:mavedb:00000053\", \"urn:mavedb:00000058-a-1\"))):\n",
    "                    seq = tx_selection[ss].sequence\n",
    "                    sub_var[\"vrs_ref_allele_seq\"] = seq[start_end[0]:start_end[1]]\n",
    "                else:\n",
    "                    seq = sub_var[\"location\"][\"sequence_id\"]\n",
    "                    sub_var[\"vrs_ref_allele_seq\"] = dp.get_sequence(seq, start_end[0],\n",
    "                                                                    start_end[1])\n",
    "        else:\n",
    "            start_end = format_start_end(ss, start=variant_list[\"location\"][\"interval\"]\n",
    "                                             [\"start\"][\"value\"],\n",
    "                                             end=variant_list[\"location\"][\"interval\"]\n",
    "                                             [\"end\"][\"value\"])\n",
    "            if (ss.startswith((\"urn:mavedb:00000047\", \"urn:mavedb:00000048\",\n",
    "                               \"urn:mavedb:00000053\", \"urn:mavedb:00000058-a-1\"))):\n",
    "                seq = tx_selection[ss].sequence\n",
    "                variant_list[\"vrs_ref_allele_seq\"] = seq[start_end[0]:start_end[1]]\n",
    "            else:\n",
    "                seq = variant_list[\"location\"][\"sequence_id\"]\n",
    "                variant_list[\"vrs_ref_allele_seq\"] = dp.get_sequence(seq, start_end[0],\n",
    "                                                                     start_end[1])\n",
    "\n",
    "        # Determine reference sequence\n",
    "        if var.layer == AnnotationLayer.GENOMIC:\n",
    "            if \"members\" in variant_list:\n",
    "                acc = get_chromosome_identifier_from_vrs_id(var.post_mapped_variants\n",
    "                                                            [\"members\"][0][\"location\"]\n",
    "                                                            [\"sequence_id\"])\n",
    "                acc = acc.strip(\"refseq:\")\n",
    "            else:\n",
    "                acc = get_chromosome_identifier_from_vrs_id(var.post_mapped_variants\n",
    "                                                            [\"location\"]\n",
    "                                                            [\"sequence_id\"])\n",
    "                acc = acc.strip(\"refseq:\")\n",
    "        else:\n",
    "            acc = tx_selection[ss].np\n",
    "\n",
    "        # Add vrs_ref_allele_seq annotation and hgvs string to post-mapped variants\n",
    "        variant_list = var.post_mapped_variants\n",
    "        if \"members\" in variant_list:\n",
    "            for sub_var in variant_list[\"members\"]:\n",
    "                sub_var[\"vrs_ref_allele_seq\"] = dp.get_sequence(sub_var[\"location\"][\"sequence_id\"],\n",
    "                                                                sub_var[\"location\"][\"interval\"]\n",
    "                                                                    [\"start\"][\"value\"],\n",
    "                                                                sub_var[\"location\"][\"interval\"]\n",
    "                                                                    [\"end\"][\"value\"])\n",
    "                sub_var[\"hgvs\"] = get_hgvs_string(sub_var, dp, acc)\n",
    "        else:\n",
    "            variant_list[\"vrs_ref_allele_seq\"] = dp.get_sequence(variant_list[\"location\"][\"sequence_id\"],\n",
    "                                                            variant_list[\"location\"][\"interval\"]\n",
    "                                                                [\"start\"][\"value\"],\n",
    "                                                            variant_list[\"location\"][\"interval\"]\n",
    "                                                                [\"end\"][\"value\"])\n",
    "            variant_list[\"hgvs\"] = get_hgvs_string(variant_list, dp, acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Annotated VRS Mappings Dictionary\n",
    "\n",
    "Run the cell below to save the annotated VRS mappings dictionary to `analysis_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with Path.open(\"analysis_files/mave_vrs_mappings.pickle\", \"wb\") as fn:\n",
    "    pickle.dump(mave_vrs_mappings, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VRS mappings output in JSON files\n",
    "\n",
    "Run the cells below to save the VRS mappings output in a JSON file in `analysis_files/mappings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"analysis_files/mappings\")\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.schemas import AlignmentResult, TxSelectResult\n",
    "\n",
    "with Path.open(\"analysis_files/mave_blat_output.pickle\", \"rb\") as fn:\n",
    "    mave_blat_temp = pickle.load(fn)\n",
    "align_results = {}\n",
    "for ss in mave_blat_temp:\n",
    "    align_results[ss] = AlignmentResult(**mave_blat_temp[ss])\n",
    "\n",
    "with Path.open(\"analysis_files/transcript_mappings.pickle\", \"rb\") as fn:\n",
    "    transcript_mappings_temp = pickle.load(fn)\n",
    "tx_selection = {}\n",
    "for ss in transcript_mappings_temp:\n",
    "    tx_selection[ss] = TxSelectResult(**transcript_mappings_temp[ss])\n",
    "\n",
    "with Path.open(\"analysis_files/mave_vrs_mappings.pickle\", \"rb\") as fn:\n",
    "    mave_vrs_mappings = pickle.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcd_mapping.utils import save_mapped_output_json\n",
    "\n",
    "for ss in mave_vrs_mappings:\n",
    "        save_mapped_output_json(ss=ss, mave_vrs_mappings=mave_vrs_mappings[ss],\n",
    "                                align_result=align_results[ss],\n",
    "                                tx_output=tx_selection.get(ss, None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
