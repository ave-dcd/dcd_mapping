{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaveDB Mapping Analysis\n",
    "\n",
    "This notebook demonstrates how data from score sets in [MaveDB](https://mavedb.org/) can be mapped to human reference sequences and represented using the [Variation Representation Specification (VRS)](https://vrs.ga4gh.org/) of the [Global Alliance for Genomics and Health (GA4GH)](https://www.ga4gh.org/), as described in \"Mapping MAVE data for use in human genomics applications\" (Arbesfeld et al). \n",
    "\n",
    "Each step of the mapping workflow is demonstrated under the relevant header and accompanied by example data pulled from MaveDB scoreset `urn:mavedb:00000041-a-1`. After each step, data is saved to a local [pickle](https://docs.python.org/3/library/pickle.html) checkpoint file for easy use in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, initialize environment parameters to enable access to required resources:\n",
    "\n",
    "* Universal Transcript Archive (UTA): see [README](https://github.com/biocommons/uta?tab=readme-ov-file#installing-uta-locally) for setup instructions. Users with access to Docker on their local devices can use the available Docker image; otherwise, start a relatively recent (version 14+) PostgreSQL instance and add data from the `20210129b` database dump.\n",
    "* SeqRepo: see [README](https://github.com/biocommons/biocommons.seqrepo?tab=readme-ov-file#requirements) for setup instructions. Experiments here were run using the `2024-02-20` snapshot.\n",
    "* Gene Normalizer: see [documentation](https://gene-normalizer.readthedocs.io/0.3.0-dev1/install.html) for installation instructions\n",
    "  * This notebook was run using Gene Normalizer PostgreSQL data checkpointed from 2024-05-29. To sync local data against this snapshot, follow [instructions for PostgreSQL setup](https://gene-normalizer.readthedocs.io/0.3.0-dev1/managing_data/postgresql.html#local-setup) and then use the `gene_norm_update_remote` command:\n",
    "\n",
    "```shell\n",
    "$ gene_norm_update_remote --data_url=\"https://vicc-normalizers.s3.us-east-2.amazonaws.com/gene_normalization/postgresql/gene_norm_20240529154335.sql.tar.gz\"\n",
    "```\n",
    "\n",
    "* blat: Must be available on the local PATH and executable by the user. Otherwise, its location can be set manually with the `BLAT_BIN_PATH` environment variable. See the [UCSC Genome Browser FAQ](https://genome.ucsc.edu/FAQ/FAQblat.html#blat3) for download instructions. For our experiments, we placed the binary in the same directory as these notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set external resources. configure based on location of available data.\n",
    "environ[\"GENE_NORM_DB_URL\"] = \"postgresql://postgres@localhost:5432/gene_normalizer\"\n",
    "environ[\"UTA_DB_URL\"] = \"postgresql://uta_admin:uta@localhost:5432/uta/uta_20210129b\"\n",
    "environ[\"BLAT_BIN_PATH\"] = str(Path(\"blat\").absolute())\n",
    "environ[\"SEQREPO_ROOT_DIR\"] = \"/usr/local/share/seqrepo/2024-02-20\" \n",
    "environ[\"DCD_MAPPING_RESOURCES_DIR\"] = str(Path(\"./mavedb_files\").absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Output Directory\n",
    "\n",
    "Output from this notebook will be stored in a directory named `analysis_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_files_dir = Path(\"analysis_files\")\n",
    "analysis_files_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get experiment data from MaveDB\n",
    "\n",
    "Get metadata for the examined MaveDB score sets (209 in total). Each captures the following:\n",
    "\n",
    "* `urn`: The score set identifier\n",
    "* `target_gene_name`: The listed target for the score set (e.g. Src catalytic domain, CXCR4)\n",
    "* `target_sequence`: The target sequence for the score set\n",
    "* `target_sequence_type`: Is the target sequence a DNA or protein sequence\n",
    "* `target_uniprot_ref`: The Uniprot ID associated with the score set, if available\n",
    "* `target_gene_category`: The target type associated with the score set (e.g. Regulatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresets_input = Path(\"experiment_scoresets.txt\")\n",
    "with scoresets_input.open() as f:\n",
    "    scoresets = [scoreset.strip() for scoreset in f.readlines()]\n",
    "example_scoreset = \"urn:mavedb:00000041-a-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 209/209 [00:00<00:00, 5489.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from dcd_mapping.mavedb_data import get_scoreset_metadata\n",
    "\n",
    "metadata = {}\n",
    "for scoreset in tqdm(scoresets):\n",
    "    metadata[scoreset] = get_scoreset_metadata(scoreset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urn': 'urn:mavedb:00000041-a-1',\n",
       " 'target_gene_name': 'Src catalytic domain',\n",
       " 'target_gene_category': <TargetType.PROTEIN_CODING: 'Protein coding'>,\n",
       " 'target_sequence': 'CTGCGGCTGGAGGTCAAGCTGGGCCAGGGCTGCTTTGGCGAGGTGTGGATGGGGACCTGGAACGGTACCACCAGGGTGGCCATCAAAACCCTGAAGCCTGGCACGATGTCTCCAGAGGCCTTCCTGCAGGAGGCCCAGGTCATGAAGAAGCTGAGGCATGAGAAGCTGGTGCAGTTGTATGCTGTGGTTTCAGAGGAGCCCATTTACATCGTCACGGAGTACATGAGCAAGGGGAGTTTGCTGGACTTTCTCAAGGGGGAGACAGGCAAGTACCTGCGGCTGCCTCAGCTGGTGGACATGGCTGCTCAGATCGCCTCAGGCATGGCGTACGTGGAGCGGATGAACTACGTCCACCGGGACCTTCGTGCAGCCAACATCCTGGTGGGAGAGAACCTGGTGTGCAAAGTGGCCGACTTTGGGCTGGCTCGGCTCATTGAAGACAATGAGTACACGGCGCGGCAAGGTGCCAAATTCCCCATCAAGTGGACGGCTCCAGAAGCTGCCCTCTATGGCCGCTTCACCATCAAGTCGGACGTGTGGTCCTTCGGGATCCTGCTGACTGAGCTCACCACAAAGGGACGGGTGCCCTACCCTGGGATGGTGAACCGCGAGGTGCTGGACCAGGTGGAGCGGGGCTACCGGATGCCCTGCCCGCCGGAGTGTCCCGAGTCCCTGCACGACCTCATGTGCCAGTGCTGGCGGAAGGAGCCTGAGGAGCGGCCCACCTTCGAGTACCTGCAGGCCTTCCTG',\n",
       " 'target_sequence_type': <TargetSequenceType.DNA: 'dna'>,\n",
       " 'target_uniprot_ref': {'id': 'uniprot:P12931', 'offset': 269}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, get corresponding experiment scores from MaveDB. Mirroring information provided by `/scores` API endpoint, provides the following data for each score in a score set:\n",
    "\n",
    "* `hgvs_pro`: variant description with respect to the amino acid target sequence\n",
    "* `hgvs_nt`: variant description with respect to the nucleotide target sequence\n",
    "* `score`: raw reported score\n",
    "* `accession`: accession identifier for the specific experiment, e.g. `urn:mavedb:00000041-a-1#548`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 209/209 [00:07<00:00, 27.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from dcd_mapping.mavedb_data import get_scoreset_records\n",
    "\n",
    "scores = {}\n",
    "for urn in tqdm(scoresets):\n",
    "    try:\n",
    "        scores[urn] = get_scoreset_records(urn)\n",
    "    except:\n",
    "        print(urn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each score \"row\" consists of nucleotide and/or protein [MAVE-HGVS expressions](https://www.mavedb.org/docs/mavehgvs/spec.html), a score, and an identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hgvs_pro': 'p.Tyr170Gly',\n",
       " 'hgvs_nt': 'NA',\n",
       " 'score': Decimal('0.753146338'),\n",
       " 'accession': 'urn:mavedb:00000041-a-1#36'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[example_scoreset][0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MaveDB Metadata to BLAT Alignment Data\n",
    "\n",
    "During this step, the target sequence for each score set is run through BLAT, allowing for genomic coordinates to be linked with the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BLAT Output for each Score Set\n",
    "\n",
    "Generate BLAT alignment output for each examined score set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████▋                                                                                   | 55/209 [48:51<3:10:57, 74.40s/it]"
     ]
    }
   ],
   "source": [
    "from dcd_mapping.align import AlignmentError, align\n",
    "from dcd_mapping.mavedb_data import get_scoreset_metadata\n",
    "\n",
    "align_results = {}\n",
    "failed_alignment_scoresets = []\n",
    "\n",
    "for scoreset, meta in tqdm(metadata.items()):\n",
    "    try:\n",
    "        align_results[scoreset] = align(meta, silent=True)\n",
    "    except AlignmentError:\n",
    "        failed_alignment_scoresets.append(scoreset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our experiments, we found that one scoreset, `urn:mavedb:00000105-a-1`, fails to return a BLAT hit against the reference genome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failed_alignment_scoresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the alignment phase is a structured description of the best BLAT result for the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_results[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save BLAT Output\n",
    "\n",
    "Save a checkpoint for the BLAT results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "mave_blat_to_save = {}\n",
    "for scoreset, result in align_results.items():\n",
    "    mave_blat_to_save[scoreset] = result.dict()\n",
    "with (analysis_files_dir / \"mave_blat_output.pickle\").open(\"wb\") as fn:\n",
    "    pickle.dump(mave_blat_to_save, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Transcript and Offset Selection for MaveDB Score Sets\n",
    "\n",
    "In this phase, a human transcript is chosen for each protein-coding score set, and an offset is computed when the target sequence does not occur at the start of the human reference sequence. For regulatory/other non-coding score sets, a transcript is not chosen and the chromosomal sequence is selected as the reference sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BLAT output\n",
    "\n",
    "Load checkpointed BLAT output for the examined MaveDB score sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.schemas import AlignmentResult\n",
    "\n",
    "with (analysis_files_dir / \"mave_blat_output.pickle\").open(\"rb\") as fn:\n",
    "    mave_blat_temp = pickle.load(fn)\n",
    "align_results = {}\n",
    "for scoreset in scoresets:\n",
    "    align_result = mave_blat_temp.get(scoreset)\n",
    "    if align_result:\n",
    "        align_results[scoreset] = AlignmentResult(**align_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Transcript Mappings File\n",
    "\n",
    "Generate a transcript mapping for each relevant score set containing the following data:\n",
    "\n",
    "* `nm`: A RefSeq transcript accession\n",
    "* `np`: A RefSeq protein sequence accession\n",
    "* `start`: An integer containing the offset for the target sequence with the respect to the selected human reference sequence\n",
    "* `transcript_mode`: The set of [MANE annotations](https://www.ncbi.nlm.nih.gov/refseq/MANE/) in which the selected transcript is included. See the [CoolSeqTool docs](https://coolseqtool.readthedocs.io/0.4.0-dev3/transcript_selection.html#representative-transcript-priority) for additional information\n",
    "* `sequence`: The translated protein reference sequence\n",
    "* `is_full_match`: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from dcd_mapping.transcripts import TxSelectError, select_transcript\n",
    "\n",
    "nest_asyncio.apply()\n",
    "failed_tx_select_scoresets = [] \n",
    "tx_selection = {}\n",
    "for ss in tqdm(scoresets):\n",
    "    if ss in align_results:\n",
    "        try:\n",
    "            tx_selection[ss] = asyncio.run(\n",
    "                select_transcript(\n",
    "                    metadata[ss],\n",
    "                    scores[ss],\n",
    "                    align_results[ss],\n",
    "                )\n",
    "            )\n",
    "        except TxSelectError:\n",
    "            failed_tx_select_scoresets.append(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phase should be completed without encountering any new errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_tx_select_scoresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcript selection and offset data is stored for each scoreset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_selection[example_scoreset].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Transcript Mappings Output\n",
    "\n",
    "Save a checkpoint for the `transcript_mappings` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "transcript_mappings_to_save = {}\n",
    "for ss in tx_selection:\n",
    "    if tx_selection[ss]:\n",
    "        transcript_mappings_to_save[ss] = tx_selection[ss].dict()\n",
    "with (analysis_files_dir / \"transcript_mappings.pickle\").open(\"wb\") as fn:\n",
    "    pickle.dump(transcript_mappings_to_save, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Mapping MAVE Variants using the GA4GH Variation Representation Specification (VRS)\n",
    "\n",
    "During this phase, MAVE variants are supplied to VRS, generating a pre-mapped and post-mapped computable representation for each variant. The functional effect score for each variant pair and the associated MaveDB ID are also stored in separate dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Alignment and Transcript Selection Data\n",
    "\n",
    "Load checkpointed alignment and transcript selection data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.schemas import AlignmentResult, TxSelectResult\n",
    "\n",
    "with (analysis_files_dir / \"mave_blat_output.pickle\").open(\"rb\") as fn:\n",
    "    mave_blat_temp = pickle.load(fn)\n",
    "align_results = {}\n",
    "for ss in mave_blat_temp:\n",
    "    align_results[ss] = AlignmentResult(**mave_blat_temp[ss])\n",
    "\n",
    "with (analysis_files_dir / \"transcript_mappings.pickle\").open(\"rb\") as fn:\n",
    "    transcript_mappings_temp = pickle.load(fn)\n",
    "tx_selection = {}\n",
    "for ss in transcript_mappings_temp:\n",
    "    tx_selection[ss] = TxSelectResult(**transcript_mappings_temp[ss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MaveDB Variants to VRS Alleles\n",
    "\n",
    "Convert MaveDB variants to VRS objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcd_mapping.lookup import get_seqrepo\n",
    "from dcd_mapping.vrs_map import vrs_map\n",
    "from dcd_mapping.mavedb_data import get_scoreset_metadata, get_scoreset_records\n",
    "\n",
    "mave_vrs_mappings = {}\n",
    "\n",
    "for ss in tqdm(align_results):\n",
    "    mave_vrs_mappings[ss] = vrs_map(\n",
    "        metadata[ss],\n",
    "        align_results[ss],\n",
    "        scores[ss],\n",
    "        tx_selection.get(ss)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each score in a MaveDB scoreset, VRS objects are generated from both the original (pre-mapped) MAVE variation descriptions as well as the variations that have been mapped to reference transcripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mave_vrs_mappings[example_scoreset][0].model_dump(exclude_none=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VRS Mappings Dictionary\n",
    "\n",
    "Save a checkpoint of the VRS mappings dictionary to `analysis_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(analysis_files_dir / \"mave_vrs_mappings.pickle\").open(\"wb\") as fn:\n",
    "    pickle.dump(mave_vrs_mappings, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in VRS Mappings Dictionary and Transcript Selection Dictionary\n",
    "\n",
    "Read in the VRS mappings and transcript selection checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dcd_mapping.transcripts import TxSelectResult\n",
    "\n",
    "with (analysis_files_dir / \"mave_vrs_mappings.pickle\").open(\"rb\") as fn:\n",
    "    mave_vrs_mappings = pickle.load(fn)\n",
    "with (analysis_files_dir / \"transcript_mappings.pickle\").open(\"rb\") as fn:\n",
    "    transcript_mappings_temp = pickle.load(fn)\n",
    "tx_selection = {}\n",
    "for ss in transcript_mappings_temp:\n",
    "    tx_selection[ss] = TxSelectResult(**transcript_mappings_temp[ss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Annotations\n",
    "\n",
    "Finally, annotate MaveDB scoreset metadata with the pre- and post-mapped VRS objects, as well as two additional data points:\n",
    "\n",
    "1. `vrs_ref_allele_seq`: The sequence between the start and end positions indicated in the variant\n",
    "2. `hgvs`: An HGVS string describing the variant (only included for post-mapped variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcd_mapping.annotate import annotate\n",
    "\n",
    "annotated_vrs_mappings = {}\n",
    "for urn, mapping in tqdm(mave_vrs_mappings.items()):\n",
    "    if mapping:\n",
    "        annotated_vrs_mappings[urn] =  annotate(mapping, tx_selection.get(urn), metadata[urn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final product provided to our reported integration projects includes VRS 1.3-compliant alleles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_vrs_mappings[example_scoreset][0].model_dump(exclude_none=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Annotated VRS Mappings Dictionary\n",
    "\n",
    "Run the cell below to save the annotated VRS mappings dictionary to `analysis_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with (analysis_files_dir / \"mave_vrs_mappings.pickle\").open(\"wb\") as fn:\n",
    "    pickle.dump(annotated_vrs_mappings, fn, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VRS mappings output in JSON files\n",
    "\n",
    "Run the cells below to save the VRS mappings output in a JSON file in `analysis_files/mappings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcd_mapping.annotate import save_mapped_output_json\n",
    "\n",
    "mappings_dir = analysis_files_dir / \"mappings\"\n",
    "mappings_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for urn, mappings in tqdm(annotated_vrs_mappings.items()):\n",
    "    output_file = mappings_dir / f\"{urn}_mappings.json\"\n",
    "    save_mapped_output_json(\n",
    "        urn,\n",
    "        mappings,\n",
    "        align_results[urn],\n",
    "        tx_selection.get(urn),\n",
    "        include_vrs_2=True,\n",
    "        output_path=output_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mave",
   "language": "python",
   "name": "mave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
